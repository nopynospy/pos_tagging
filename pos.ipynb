{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e350a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk import pos_tag, word_tokenize, RegexpParser, Tree\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a760fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('tagsets')\n",
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c1630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP: {<DT>?<JJ>*<NN|NNS|NNP|NNPS><NN|NNS|NNP|NNPS>*}          # Chunk sequences of DT, JJ, NN\n",
    "  PP: {<IN><NP>}               # Chunk prepositions followed by NP\n",
    "  VP: {<VB.*><NP|PP|CLAUSE>+$} # Chunk verbs and their arguments\n",
    "  CLAUSE: {<NP><VP>}           # Chunk NP, VP\n",
    "  \"\"\"\n",
    "\n",
    "chunker = RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "225e6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(corpus):\n",
    "    tagged = pos_tag(word_tokenize(corpus))\n",
    "    output = chunker.parse(tagged)\n",
    "    return str(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18783ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49f8f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PunktSentenceTokenizer()\n",
    "\n",
    "def tag_pos(corpus):\n",
    "\n",
    "    tokenized = tokenizer.tokenize(corpus)\n",
    "\n",
    "    try:\n",
    "        for sent in tokenized:\n",
    "            words = nltk.word_tokenize(sent)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            return tagged\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944b7213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_and_chunk(corpus):\n",
    "    print(chunk(corpus))\n",
    "    print(\"\\n\")\n",
    "    print(tag_pos(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd5be7d",
   "metadata": {},
   "source": [
    "# Noun Phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211a9deb",
   "metadata": {},
   "source": [
    "Linguistics for English Language Teaching: Sounds, Words, and Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46c00372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP John/NNP) laughed/VBD (PP at/IN (NP the/DT cat/NN)) ./.)\n",
      "\n",
      "\n",
      "[('John', 'NNP'), ('laughed', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('cat', 'NN'), ('.', '.')]\n",
      "None\n",
      "\n",
      "\n",
      "(S (NP Mailmen/NNS) laughed/VBD (PP at/IN (NP the/DT cat/NN)) ./.)\n",
      "\n",
      "\n",
      "[('Mailmen', 'NNS'), ('laughed', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('cat', 'NN'), ('.', '.')]\n",
      "None\n",
      "\n",
      "\n",
      "(S\n",
      "  Most/JJS\n",
      "  (NP students/NNS)\n",
      "  laughed/VBN\n",
      "  (PP at/IN (NP the/DT cat/NN))\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('Most', 'JJS'), ('students', 'NNS'), ('laughed', 'VBN'), ('at', 'IN'), ('the', 'DT'), ('cat', 'NN'), ('.', '.')]\n",
      "None\n",
      "\n",
      "\n",
      "(S\n",
      "  (NP Many/JJ americans/NNS)\n",
      "  laughed/VBN\n",
      "  (PP at/IN (NP the/DT cat/NN))\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('Many', 'JJ'), ('americans', 'NNS'), ('laughed', 'VBN'), ('at', 'IN'), ('the', 'DT'), ('cat', 'NN'), ('.', '.')]\n",
      "None\n",
      "\n",
      "\n",
      "(S\n",
      "  A/DT\n",
      "  huge/JJ\n",
      "  ,/,\n",
      "  (NP loveable/JJ bear/NN)\n",
      "  laughed/VBN\n",
      "  (PP at/IN (NP the/DT cat/NN))\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('A', 'DT'), ('huge', 'JJ'), (',', ','), ('loveable', 'JJ'), ('bear', 'NN'), ('laughed', 'VBN'), ('at', 'IN'), ('the', 'DT'), ('cat', 'NN'), ('.', '.')]\n",
      "None\n",
      "\n",
      "\n",
      "(S\n",
      "  (NP A/DT student/NN)\n",
      "  (PP from/IN (NP brazil/NN))\n",
      "  laughed/VBN\n",
      "  (PP at/IN (NP the/DT cat/NN))\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('A', 'DT'), ('student', 'NN'), ('from', 'IN'), ('brazil', 'NN'), ('laughed', 'VBN'), ('at', 'IN'), ('the', 'DT'), ('cat', 'NN'), ('.', '.')]\n",
      "None\n",
      "\n",
      "\n",
      "(S\n",
      "  (NP The/DT table/NN)\n",
      "  (PP in/IN (NP the/DT corner/NN))\n",
      "  laughed/VBD\n",
      "  (PP at/IN (NP the/DT cat/NN))\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('The', 'DT'), ('table', 'NN'), ('in', 'IN'), ('the', 'DT'), ('corner', 'NN'), ('laughed', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('cat', 'NN'), ('.', '.')]\n",
      "None\n",
      "\n",
      "\n",
      "(S\n",
      "  (NP The/DT people/NNS)\n",
      "  we/PRP\n",
      "  interviewed/VBD\n",
      "  laughed/VBN\n",
      "  (PP at/IN (NP the/DT cat/NN))\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('The', 'DT'), ('people', 'NNS'), ('we', 'PRP'), ('interviewed', 'VBD'), ('laughed', 'VBN'), ('at', 'IN'), ('the', 'DT'), ('cat', 'NN'), ('.', '.')]\n",
      "None\n",
      "\n",
      "\n",
      "(S\n",
      "  (NP John/NNP)\n",
      "  and/CC\n",
      "  his/PRP$\n",
      "  (NP friends/NNS)\n",
      "  laughed/VBN\n",
      "  (PP at/IN (NP the/DT cat/NN))\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('John', 'NNP'), ('and', 'CC'), ('his', 'PRP$'), ('friends', 'NNS'), ('laughed', 'VBN'), ('at', 'IN'), ('the', 'DT'), ('cat', 'NN'), ('.', '.')]\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noun_phrases = [ \"John\",\n",
    " \"mailmen\",\n",
    " \"most students\", \n",
    " \"many Americans\",\n",
    " \"a huge, loveable bear\",\n",
    " \"a student from brazil\",\n",
    " \"the table in the corner\",\n",
    " \"the people we interviewed\",\n",
    "\"John and his friends\"]\n",
    "\n",
    "for np in noun_phrases:\n",
    "    np = np.capitalize()\n",
    "    np += \" laughed at the cat.\"\n",
    "    print(tag_and_chunk(np))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c84a85",
   "metadata": {},
   "source": [
    "Many and most are considred as adverbs, but they can also be quantifiers.\n",
    "His can be pronoun and determiner, here it is treated as pronoun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b507d600",
   "metadata": {},
   "source": [
    "English Syntax: An Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95408c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S His/PRP$ (NP friend/NN) learned/VBD (NP dancing/NN) ./.)\n",
      "\n",
      "\n",
      "[('His', 'PRP$'), ('friend', 'NN'), ('learned', 'VBD'), ('dancing', 'NN'), ('.', '.')]\n",
      "None\n",
      "\n",
      "\n",
      "(S\n",
      "  My/PRP$\n",
      "  (NP bother/NN ’/NNP s/NN friend/NN)\n",
      "  learned/VBD\n",
      "  (NP dancing/NN)\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('My', 'PRP$'), ('bother', 'NN'), ('’', 'NNP'), ('s', 'NN'), ('friend', 'NN'), ('learned', 'VBD'), ('dancing', 'NN'), ('.', '.')]\n",
      "None\n",
      "\n",
      "\n",
      "(S\n",
      "  (NP The/DT president/NN ’/NNP)\n",
      "  s/VBZ\n",
      "  bodyguard/RB\n",
      "  learned/VBN\n",
      "  (NP surveillance/NN)\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('The', 'DT'), ('president', 'NN'), ('’', 'NNP'), ('s', 'VBZ'), ('bodyguard', 'RB'), ('learned', 'VBN'), ('surveillance', 'NN'), ('.', '.')]\n",
      "None\n",
      "\n",
      "\n",
      "(S\n",
      "  (NP The/DT King/NNP)\n",
      "  (PP of/IN (NP Rock/NNP))\n",
      "  and/CC\n",
      "  (NP Roll/NNP ’/NNP s/NN records/NNS)\n",
      "  led/VBD\n",
      "  to/TO\n",
      "  dancing/VBG\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('The', 'DT'), ('King', 'NNP'), ('of', 'IN'), ('Rock', 'NNP'), ('and', 'CC'), ('Roll', 'NNP'), ('’', 'NNP'), ('s', 'NN'), ('records', 'NNS'), ('led', 'VBD'), ('to', 'TO'), ('dancing', 'VBG'), ('.', '.')]\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = [ \"His friend learned dancing.\",\n",
    " \"My bother’s friend learned dancing.\",\n",
    " \"The president’s bodyguard learned surveillance.\", \n",
    " \"The King of Rock and Roll’s records led to dancing.\"]\n",
    "\n",
    "for s in sentences:\n",
    "    print(tag_and_chunk(s))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c548712d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S I/PRP am/VBP (PP at/IN (NP the/DT bus/NN stop/NN)) ./.)\n",
      "\n",
      "\n",
      "[('I', 'PRP'), ('am', 'VBP'), ('at', 'IN'), ('the', 'DT'), ('bus', 'NN'), ('stop', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "compund_noun = \"I am at the bus stop.\"\n",
    "tag_and_chunk(compund_noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a3c4a",
   "metadata": {},
   "source": [
    "## Possesive Determiner\n",
    "\n",
    "Possesive determiner should be seperated from possesive pronoun. His, hers, mine is not followed by another noun, but his, her and my are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddf892bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S My/PRP$ learned/VBD dancing/VBG)\n",
      "\n",
      "\n",
      "[('My', 'PRP$'), ('learned', 'VBD'), ('dancing', 'VBG')]\n",
      "(S Our/PRP$ (VP learned/VBD (NP dancing/NN)))\n",
      "\n",
      "\n",
      "[('Our', 'PRP$'), ('learned', 'VBD'), ('dancing', 'NN')]\n",
      "(S Your/PRP$ (VP learned/VBD (NP dancing/NN)))\n",
      "\n",
      "\n",
      "[('Your', 'PRP$'), ('learned', 'VBD'), ('dancing', 'NN')]\n",
      "(S His/PRP$ (VP learned/VBD (NP dancing/NN)))\n",
      "\n",
      "\n",
      "[('His', 'PRP$'), ('learned', 'VBD'), ('dancing', 'NN')]\n",
      "(S Her/PRP$ (VP learned/VBD (NP dancing/NN)))\n",
      "\n",
      "\n",
      "[('Her', 'PRP$'), ('learned', 'VBD'), ('dancing', 'NN')]\n",
      "(S Their/PRP$ (VP learned/VBD (NP dancing/NN)))\n",
      "\n",
      "\n",
      "[('Their', 'PRP$'), ('learned', 'VBD'), ('dancing', 'NN')]\n",
      "(S Its/PRP$ (VP learned/VBD (NP dancing/NN)))\n",
      "\n",
      "\n",
      "[('Its', 'PRP$'), ('learned', 'VBD'), ('dancing', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "pos_dets = [\"my\", \"our\", \"your\", \"his\", \"her\", \"their\", \"its\"]\n",
    "\n",
    "for pos_dt in pos_dets:\n",
    "    sent = pos_dt + \" learned dancing\"\n",
    "    sent = sent.capitalize()\n",
    "    tag_and_chunk(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33dfe1e",
   "metadata": {},
   "source": [
    "In every instance, considering possesive determiners as pronouns causes chunking issues in noun phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db141c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Cat/NNP friend/NN) learned/VBD (NP dancing/NN) ./.)\n",
      "\n",
      "\n",
      "[('Cat', 'NNP'), ('friend', 'NN'), ('learned', 'VBD'), ('dancing', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tag_and_chunk(\"Cat friend learned dancing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6177da62",
   "metadata": {},
   "source": [
    "Because the grammar set earlier already includes compound noun, converting the possesive determiners to a random noun fixes the noun phrase chunking issue in possesive determiner + noun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a380f9f3",
   "metadata": {},
   "source": [
    "## Demonstrative determiners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d68e56ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP This/DT cat/NN) can/MD swim/VB ./.)\n",
      "\n",
      "\n",
      "[('This', 'DT'), ('cat', 'NN'), ('can', 'MD'), ('swim', 'VB'), ('.', '.')]\n",
      "(S (NP That/DT cat/NN) can/MD swim/VB ./.)\n",
      "\n",
      "\n",
      "[('That', 'DT'), ('cat', 'NN'), ('can', 'MD'), ('swim', 'VB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "s_dem_dets = [\"this\", \"that\"]\n",
    "\n",
    "for s_dem in s_dem_dets:\n",
    "    sent = s_dem + \" cat can swim.\"\n",
    "    sent = sent.capitalize()\n",
    "    tag_and_chunk(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c24d52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP These/DT cats/NNS) can/MD swim/VB ./.)\n",
      "\n",
      "\n",
      "[('These', 'DT'), ('cats', 'NNS'), ('can', 'MD'), ('swim', 'VB'), ('.', '.')]\n",
      "(S (NP Those/DT cats/NNS) can/MD swim/VB ./.)\n",
      "\n",
      "\n",
      "[('Those', 'DT'), ('cats', 'NNS'), ('can', 'MD'), ('swim', 'VB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "p_dem_dets = [\"these\", \"those\"]\n",
    "\n",
    "for p_dem in p_dem_dets:\n",
    "    sent = p_dem + \" cats can swim.\"\n",
    "    sent = sent.capitalize()\n",
    "    tag_and_chunk(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6805763b",
   "metadata": {},
   "source": [
    "No issue for demonstrative determiners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313f6b0",
   "metadata": {},
   "source": [
    "## Articles (Can be considered as determiners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8568dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP The/DT cat/NN) can/MD fly/VB ./.)\n",
      "\n",
      "\n",
      "[('The', 'DT'), ('cat', 'NN'), ('can', 'MD'), ('fly', 'VB'), ('.', '.')]\n",
      "(S (NP A/DT cat/NN) can/MD fly/VB ./.)\n",
      "\n",
      "\n",
      "[('A', 'DT'), ('cat', 'NN'), ('can', 'MD'), ('fly', 'VB'), ('.', '.')]\n",
      "(S (NP An/DT orange/NN) can/MD fly/VB ./.)\n",
      "\n",
      "\n",
      "[('An', 'DT'), ('orange', 'NN'), ('can', 'MD'), ('fly', 'VB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "art_nouns = [\"the cat\", \"a cat\", \"an orange\"]\n",
    "\n",
    "for art_noun in art_nouns:\n",
    "    sent = art_noun + \" can fly.\"\n",
    "    sent = sent.capitalize()\n",
    "    tag_and_chunk(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf5b94",
   "metadata": {},
   "source": [
    "No issue for articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79624793",
   "metadata": {},
   "source": [
    "## Quantifiers (as determiners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28269dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantifiers = [\"all\", \"some\", \"many\", \"lot\", \"lots\", \"ton\", \"tons\", \"bit\", \"no\", \"every\", \"enough\", \"little\",\n",
    " \"much\", \"more\", \"most\", \"plenty\", \"several\", \"few\", \"fewer\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40b879b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S I/PRP love/VBP (NP blue/NN) ./.)\n",
      "\n",
      "\n",
      "[('I', 'PRP'), ('love', 'VBP'), ('blue', 'NN'), ('.', '.')]\n",
      "(S (NP The/DT blue/NN car/NN) is/VBZ gone/VBN ./.)\n",
      "\n",
      "\n",
      "[('The', 'DT'), ('blue', 'NN'), ('car', 'NN'), ('is', 'VBZ'), ('gone', 'VBN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tag_and_chunk(\"I love blue.\")\n",
    "tag_and_chunk(\"The blue car is gone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdee6e2",
   "metadata": {},
   "source": [
    "It cannot distinguish between colour as a noun vs. as an adjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80362be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S I/PRP can/MD help/VB you/PRP ./.)\n",
      "\n",
      "\n",
      "[('I', 'PRP'), ('can', 'MD'), ('help', 'VB'), ('you', 'PRP'), ('.', '.')]\n",
      "(S (NP The/DT tin/NN) can/MD is/VBZ red/JJ ./.)\n",
      "\n",
      "\n",
      "[('The', 'DT'), ('tin', 'NN'), ('can', 'MD'), ('is', 'VBZ'), ('red', 'JJ'), ('.', '.')]\n",
      "(S (NP The/DT tin/NN cans/NNS) are/VBP red/JJ ./.)\n",
      "\n",
      "\n",
      "[('The', 'DT'), ('tin', 'NN'), ('cans', 'NNS'), ('are', 'VBP'), ('red', 'JJ'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tag_and_chunk(\"I can help you.\")\n",
    "tag_and_chunk(\"The tin can is red.\")\n",
    "tag_and_chunk(\"The tin cans are red.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa09ad5",
   "metadata": {},
   "source": [
    "It can detect cans, but not distinguish between can as a modal verb and can as a singular noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b70a4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Test/NNP) your/PRP$ might/MD ./.)\n",
      "\n",
      "\n",
      "[('Test', 'NNP'), ('your', 'PRP$'), ('might', 'MD'), ('.', '.')]\n",
      "(S Test/VB your/PRP$ (NP mights/NNS) ./.)\n",
      "\n",
      "\n",
      "[('Test', 'VB'), ('your', 'PRP$'), ('mights', 'NNS'), ('.', '.')]\n",
      "(S I/PRP might/MD be/VB late/RB ./.)\n",
      "\n",
      "\n",
      "[('I', 'PRP'), ('might', 'MD'), ('be', 'VB'), ('late', 'RB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tag_and_chunk(\"Test your might.\")\n",
    "tag_and_chunk(\"Test your mights.\")\n",
    "tag_and_chunk(\"I might be late.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c083f99",
   "metadata": {},
   "source": [
    "# Coordinating Conjunction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc8462d",
   "metadata": {},
   "source": [
    "https://grammar.yourdictionary.com/parts-of-speech/conjunctions/coordinating-conjunctions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "013824ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  go/VBP\n",
      "  to/TO\n",
      "  (NP the/DT park/NN)\n",
      "  (NP every/DT Sunday/NNP)\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('I', 'PRP'), ('go', 'VBP'), ('to', 'TO'), ('the', 'DT'), ('park', 'NN'), ('every', 'DT'), ('Sunday', 'NNP'), ('.', '.')]\n",
      "(S I/PRP long/RB to/TO see/VB his/PRP$ (NP face/NN) ./.)\n",
      "\n",
      "\n",
      "[('I', 'PRP'), ('long', 'RB'), ('to', 'TO'), ('see', 'VB'), ('his', 'PRP$'), ('face', 'NN'), ('.', '.')]\n",
      "(S\n",
      "  I/PRP\n",
      "  go/VBP\n",
      "  to/TO\n",
      "  (NP the/DT park/NN)\n",
      "  (NP every/DT Sunday/NNP)\n",
      "  ,/,\n",
      "  for/IN\n",
      "  I/PRP\n",
      "  long/JJ\n",
      "  to/TO\n",
      "  see/VB\n",
      "  his/PRP$\n",
      "  (NP face/NN)\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('I', 'PRP'), ('go', 'VBP'), ('to', 'TO'), ('the', 'DT'), ('park', 'NN'), ('every', 'DT'), ('Sunday', 'NNP'), (',', ','), ('for', 'IN'), ('I', 'PRP'), ('long', 'JJ'), ('to', 'TO'), ('see', 'VB'), ('his', 'PRP$'), ('face', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tag_and_chunk(\"I go to the park every Sunday.\")\n",
    "tag_and_chunk(\"I long to see his face.\")\n",
    "for_conj = \"I go to the park every Sunday, for I long to see his face.\"\n",
    "tag_and_chunk(for_conj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa68e8f5",
   "metadata": {},
   "source": [
    "NLTK treats for as an adverb, but it can also be coordinating conjuction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "281c7794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  like/VBP\n",
      "  to/TO\n",
      "  read/VB\n",
      "  ,/,\n",
      "  and/CC\n",
      "  I/PRP\n",
      "  write/VBP\n",
      "  in/IN\n",
      "  my/PRP$\n",
      "  (NP journal/NN)\n",
      "  (NP every/DT night/NN)\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('I', 'PRP'), ('like', 'VBP'), ('to', 'TO'), ('read', 'VB'), (',', ','), ('and', 'CC'), ('I', 'PRP'), ('write', 'VBP'), ('in', 'IN'), ('my', 'PRP$'), ('journal', 'NN'), ('every', 'DT'), ('night', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "and_conj = \"I like to read, and I write in my journal every night.\"\n",
    "tag_and_chunk(and_conj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "111edf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  You/PRP\n",
      "  should/MD\n",
      "  invite/VB\n",
      "  (NP Mario/NNP)\n",
      "  and/CC\n",
      "  (NP Estefan/NNP)\n",
      "  to/TO\n",
      "  (NP the/DT party/NN)\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('You', 'PRP'), ('should', 'MD'), ('invite', 'VB'), ('Mario', 'NNP'), ('and', 'CC'), ('Estefan', 'NNP'), ('to', 'TO'), ('the', 'DT'), ('party', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "and_conj = \"You should invite Mario and Estefan to the party.\"\n",
    "tag_and_chunk(and_conj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48db660",
   "metadata": {},
   "source": [
    "And is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fed94c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  My/PRP$\n",
      "  (NP sister/NN doesn/NN ’/NNP t/NN)\n",
      "  like/IN\n",
      "  to/TO\n",
      "  study/VB\n",
      "  ,/,\n",
      "  nor/CC\n",
      "  does/VBZ\n",
      "  she/PRP\n",
      "  take/VB\n",
      "  (NP notes/NNS)\n",
      "  (PP in/IN (NP class/NN))\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('My', 'PRP$'), ('sister', 'NN'), ('doesn', 'NN'), ('’', 'NNP'), ('t', 'NN'), ('like', 'IN'), ('to', 'TO'), ('study', 'VB'), (',', ','), ('nor', 'CC'), ('does', 'VBZ'), ('she', 'PRP'), ('take', 'VB'), ('notes', 'NNS'), ('in', 'IN'), ('class', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "nor_conj = \"My sister doesn’t like to study, nor does she take notes in class.\"\n",
    "tag_and_chunk(nor_conj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520c8ff0",
   "metadata": {},
   "source": [
    "Nor is accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71746c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Television/NN)\n",
      "  is/VBZ\n",
      "  (NP a/DT wonderful/JJ escape/NN)\n",
      "  ,/,\n",
      "  but/CC\n",
      "  it/PRP\n",
      "  interferes/VBZ\n",
      "  with/IN\n",
      "  my/PRP$\n",
      "  (NP writing/NN)\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('Television', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('wonderful', 'JJ'), ('escape', 'NN'), (',', ','), ('but', 'CC'), ('it', 'PRP'), ('interferes', 'VBZ'), ('with', 'IN'), ('my', 'PRP$'), ('writing', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "but_conj = \"Television is a wonderful escape, but it interferes with my writing.\"\n",
    "tag_and_chunk(but_conj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa53149d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  We/PRP\n",
      "  could/MD\n",
      "  have/VB\n",
      "  dinner/VBN\n",
      "  (PP before/IN (NP the/DT movie/NN))\n",
      "  ,/,\n",
      "  or/CC\n",
      "  we/PRP\n",
      "  could/MD\n",
      "  grab/VB\n",
      "  (NP a/DT bite/JJ afterward/NN)\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('We', 'PRP'), ('could', 'MD'), ('have', 'VB'), ('dinner', 'VBN'), ('before', 'IN'), ('the', 'DT'), ('movie', 'NN'), (',', ','), ('or', 'CC'), ('we', 'PRP'), ('could', 'MD'), ('grab', 'VB'), ('a', 'DT'), ('bite', 'JJ'), ('afterward', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "or_conj = \"We could have dinner before the movie, or we could grab a bite afterward.\"\n",
    "tag_and_chunk(or_conj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c9963f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  can/MD\n",
      "  ’/VB\n",
      "  t/JJ\n",
      "  decide/IN\n",
      "  if/IN\n",
      "  I/PRP\n",
      "  should/MD\n",
      "  study/VB\n",
      "  (NP economics/NNS)\n",
      "  or/CC\n",
      "  (NP political/JJ science/NN)\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('I', 'PRP'), ('can', 'MD'), ('’', 'VB'), ('t', 'JJ'), ('decide', 'IN'), ('if', 'IN'), ('I', 'PRP'), ('should', 'MD'), ('study', 'VB'), ('economics', 'NNS'), ('or', 'CC'), ('political', 'JJ'), ('science', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "or_conj = \"I can’t decide if I should study economics or political science.\"\n",
    "tag_and_chunk(or_conj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac2548aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  always/RB\n",
      "  take/VBP\n",
      "  (NP a/DT book/NN)\n",
      "  to/TO\n",
      "  (NP the/DT beach/NN)\n",
      "  ,/,\n",
      "  yet/RB\n",
      "  I/PRP\n",
      "  never/RB\n",
      "  seem/VBP\n",
      "  to/TO\n",
      "  turn/VB\n",
      "  (NP a/DT single/JJ page/NN)\n",
      "  ./.)\n",
      "\n",
      "\n",
      "[('I', 'PRP'), ('always', 'RB'), ('take', 'VBP'), ('a', 'DT'), ('book', 'NN'), ('to', 'TO'), ('the', 'DT'), ('beach', 'NN'), (',', ','), ('yet', 'RB'), ('I', 'PRP'), ('never', 'RB'), ('seem', 'VBP'), ('to', 'TO'), ('turn', 'VB'), ('a', 'DT'), ('single', 'JJ'), ('page', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "yet_conj = \"I always take a book to the beach, yet I never seem to turn a single page.\"\n",
    "tag_and_chunk(yet_conj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474700c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
